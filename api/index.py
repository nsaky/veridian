"""
Veridian API v3.0 - THE BRAIN (True Generative AI - ZERO Hardcoded Responses)
STRICT RULE: Every response MUST be generated by Gemini 1.5 Flash
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import json
import os
import pandas as pd
import re

# Initialize FastAPI
app = FastAPI(title="Veridian API v3.0 - The Brain")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load property data
DATA_PATH = os.path.join(os.path.dirname(__file__), "data", "pune_properties.json")
try:
    with open(DATA_PATH, 'r') as f:
        PROPERTIES_DATA = json.load(f)
    PROPERTIES_DF = pd.DataFrame(PROPERTIES_DATA)
    print(f"‚úÖ Loaded {len(PROPERTIES_DATA)} properties")
except Exception as e:
    print(f"‚ùå Error loading data: {e}")
    PROPERTIES_DATA = []
    PROPERTIES_DF = pd.DataFrame()

# ============================================================================
# REQUEST/RESPONSE MODELS
# ============================================================================

class ChatRequest(BaseModel):
    message: str
    user_profile: Dict[str, Any]
    conversation_history: Optional[List[Dict]] = []

class ChatResponse(BaseModel):
    reply: str
    map_action: Optional[Dict[str, Any]] = None

class ScoreRequest(BaseModel):
    property_id: str
    user_profile: Dict[str, Any]

# ============================================================================
# THE BRAIN: PURE GEMINI AI (NO HARDCODED RESPONSES)
# ============================================================================

def extract_search_criteria(message: str) -> Dict:
    """
    Extract search criteria from user message using regex
    Returns filters for Pandas DataFrame
    """
    message_lower = message.lower()
    filters = {}
    
    # Check if this is a property-specific query (e.g., "Analyze property PROP_0378")
    prop_id_match = re.search(r'prop(?:erty)?[_\s]+(\d{4})', message_lower)
    if prop_id_match:
        filters["property_id"] = f"PROP_{prop_id_match.group(1)}"
    
    # Property Type
    if any(word in message_lower for word in ["villa", "villas"]):
        filters["property_type"] = "Villa"
    elif any(word in message_lower for word in ["plot", "plots", "land"]):
        filters["property_type"] = "Plot"
    elif any(word in message_lower for word in ["commercial", "shop", "office"]):
        filters["property_type"] = "Commercial"
    elif any(word in message_lower for word in ["apartment", "flat", "bhk"]):
        filters["property_type"] = "Apartment"
    
    # Locality
    localities = ["Baner", "Hinjewadi", "Wagholi", "Kothrud", "Viman Nagar", 
                  "Koregaon Park", "Magarpatta", "Aundh"]
    for loc in localities:
        if loc.lower() in message_lower:
            filters["locality"] = loc
            break
    
    # Price - improved regex to catch various patterns
    # Matches: "under 2cr", "below 3 crore", "2cr", "under ‚Çπ2 crore", etc.
    price_match = re.search(r'(?:under|below|up to|max|maximum)?\s*(?:‚Çπ|rs\.?|inr)?\s*(\d+(?:\.\d+)?)\s*(?:cr|crore|lakh|l)', message_lower)
    if price_match:
        amount = float(price_match.group(1))
        # Check if it's lakhs or crores
        if 'lakh' in message_lower or 'l' in message_lower:
            filters["max_price"] = int(amount * 100000)
        else:  # crores
            filters["max_price"] = int(amount * 10000000)
    
    # Bedrooms
    bhk_match = re.search(r'(\d+)\s*bhk', message_lower)
    if bhk_match:
        filters["bedrooms"] = int(bhk_match.group(1))
    
    # Safe/Legal properties
    if any(word in message_lower for word in ["safe", "secure", "legal", "no risk"]):
        filters["safe"] = True
    
    # Risky properties
    if any(word in message_lower for word in ["risky", "risk", "litigation", "legal issue"]):
        filters["risky"] = True
    
    # High yield
    if any(word in message_lower for word in ["yield", "rental income"]):
        filters["high_yield"] = True
    
    # High growth/appreciation
    if any(word in message_lower for word in ["growth", "appreciation", "capital gain"]):
        filters["high_growth"] = True
    
    return filters

def filter_properties_by_criteria(filters: Dict) -> pd.DataFrame:
    """
    Filter DataFrame based on extracted criteria
    Returns filtered DataFrame
    """
    df = PROPERTIES_DF.copy()
    
    # If specific property ID requested, return only that property
    if filters.get("property_id"):
        df = df[df["id"] == filters["property_id"]]
        return df
    
    # Basic filters
    if filters.get("property_type"):
        df = df[df["property_type"] == filters["property_type"]]
    
    if filters.get("locality"):
        df = df[df["locality"] == filters["locality"]]
    
    if filters.get("max_price"):
        df = df[df["price"] <= filters["max_price"]]
    
    if filters.get("bedrooms"):
        df = df[df["bedrooms"] == filters["bedrooms"]]
    
    # Advanced filters
    if filters.get("safe"):
        df = df[(df["litigation"] == 0) & (df["rera_status"] == "Approved")]
    
    if filters.get("risky"):
        df = df[(df["litigation"] > 0) | (df["rera_status"] == "Revoked")]
    
    if filters.get("high_yield"):
        df = df[df["rental_yield"] >= 3.5]
    
    if filters.get("high_growth"):
        df = df[df["appreciation"] >= 45]
    
    return df

def create_context_string(df: pd.DataFrame, limit: int = 15) -> str:
    """
    Convert filtered DataFrame to context string for Gemini
    Returns TOP matching properties in compressed format
    """
    if df.empty:
        return "NO_PROPERTIES_FOUND"
    
    # Sort by a composite score (appreciation * yield factor)
    df_sorted = df.copy()
    df_sorted['composite_score'] = df_sorted['appreciation'] * (1 + df_sorted['rental_yield'] / 10)
    df_sorted = df_sorted.sort_values('composite_score', ascending=False)
    
    top_results = df_sorted.head(limit)
    
    # Create compact context
    context_items = []
    for _, row in top_results.iterrows():
        item = {
            "id": row["id"],
            "title": row["title"],
            "type": row["property_type"],
            "locality": row["locality"],
            "price_cr": round(row["price"] / 10000000, 2),
            "bedrooms": row["bedrooms"],
            "rental_yield": row["rental_yield"],
            "appreciation_5y": row["appreciation"],
            "rera_status": row["rera_status"],
            "litigation": row["litigation"],
            "developer": row["developer"],
            "distance_metro_km": row["distance_metro"],
            "latitude": row["lat"],
            "longitude": row["lng"]
        }
        context_items.append(item)
    
    return json.dumps(context_items, indent=2)

def call_gemini_brain(user_message: str, context: str, filters: Dict, user_profile: Dict) -> Dict:
    """
    THE BRAIN: Call Gemini 2.0 Flash using NEW SDK
    STRICT: No fallback responses allowed
    """
    try:
        from google import genai
        
        # Get API key
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise Exception("CRITICAL ERROR: GEMINI_API_KEY not found in environment")
        
        # Configure NEW Gemini client - pass key directly
        client = genai.Client(api_key=api_key)
        
        # Build the master prompt
        if context == "NO_PROPERTIES_FOUND":
            system_prompt = f"""You are Veridian, a Real Estate Investment Analyst AI.

USER QUESTION: "{user_message}"
USER RISK PROFILE: {user_profile.get('risk', 'Moderate')}

CRITICAL SITUATION: NO properties match the user's criteria in our database.

YOU MUST respond with ONLY this JSON (no markdown, no extra text):
{{
  "reply": "I couldn't find any properties matching your exact criteria. Try expanding your budget, choosing a different location, or selecting a different property type.",
  "map_action": {{
    "type": "RESET",
    "payload": {{}}
  }}
}}"""
        else:
            # Calculate center lat/lng from filtered properties
            context_data = json.loads(context)
            ids_list = [item["id"] for item in context_data]
            
            # Get center coordinates based on locality or from properties
            # Locality coordinates for major Pune areas
            locality_coords = {
                "Baner": {"lat": 18.5590, "lng": 73.7868, "zoom": 14},
                "Hinjewadi": {"lat": 18.5913, "lng": 73.7389, "zoom": 14},
                "Viman Nagar": {"lat": 18.5679, "lng": 73.9143, "zoom": 14},
                "Koregaon Park": {"lat": 18.5362, "lng": 73.8958, "zoom": 14},
                "Wagholi": {"lat": 18.5833, "lng": 73.9833, "zoom": 14},
                "Kothrud": {"lat": 18.5074, "lng": 73.8077, "zoom": 14},
                "Magarpatta": {"lat": 18.5152, "lng": 73.9283, "zoom": 14},
                "Aundh": {"lat": 18.5590, "lng": 73.8074, "zoom": 14}
            }
            
            # Use locality coordinates if available, otherwise calculate from properties
            if filters.get('locality') and filters['locality'] in locality_coords:
                coords = locality_coords[filters['locality']]
                center_lat = coords['lat']
                center_lng = coords['lng']
                zoom_level = coords['zoom']
            elif len(context_data) > 0:
                # Calculate average from top 3 properties
                center_lat = sum(item['latitude'] for item in context_data[:3]) / min(3, len(context_data))
                center_lng = sum(item['longitude'] for item in context_data[:3]) / min(3, len(context_data))
                # Zoom based on number of results: fewer results = more zoom
                zoom_level = 15 if len(ids_list) <= 5 else 14 if len(ids_list) <= 15 else 13
            else:
                center_lat = 18.5204
                center_lng = 73.8567
                zoom_level = 12
            
            system_prompt = f"""You are Veridian, a Real Estate Investment Analyst AI.

LIVE PROPERTY DATA (TOP MATCHES FOR THIS QUERY):
{context}

USER QUESTION: "{user_message}"
USER RISK PROFILE: {user_profile.get('risk', 'Moderate')}

YOUR INSTRUCTIONS:
1. ANALYZE the data to answer the user's question dynamically
2. If they ask "which is best", pick the one with highest yield OR appreciation
3. If they ask about risk, identify properties with litigation>0 or rera_status="Revoked"
4. Be specific: mention property names, exact numbers (yield %, appreciation %)
5. Warn about risky properties by name
6. DO NOT use generic responses like "I found properties" - be SPECIFIC

RESPONSE FORMAT (STRICT JSON, NO MARKDOWN):
{{
  "reply": "Your detailed, specific analysis here. Mention property names and numbers.",
  "map_action": {{
    "type": "FILTER_AND_FLY",
    "payload": {{
      "ids": {json.dumps(ids_list[:10])},
      "locality": "{filters.get('locality', '')}",
      "property_type": "{filters.get('property_type', '')}",
      "center_lat": {center_lat},
      "center_lng": {center_lng},
      "zoom": {zoom_level}
    }}
  }}
}}

CRITICAL RULES:
- Answer MUST reference specific properties from the data
- Numbers MUST be exact from the data
- If user asks "which property", name ONE specific property
- If user asks "are there risks", identify specific risky properties
- NEVER say "I found properties" without naming them

OUTPUT ONLY THE JSON OBJECT:"""

        # Call Gemini using NEW SDK
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=system_prompt
        )
        
        response_text = response.text.strip()
        
        # Clean response (remove markdown if present)
        if response_text.startswith("```"):
            lines = response_text.split("\n")
            response_text = "\n".join(lines[1:-1])
            if response_text.startswith("json"):
                response_text = response_text[4:].strip()
        
        # Parse JSON
        try:
            result = json.loads(response_text)
        except json.JSONDecodeError as e:
            # If JSON parsing fails, try to extract JSON from text
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(0))
            else:
                # If still can't parse, create structured response from text
                result = {
                    "reply": response_text,
                    "map_action": {
                        "type": "FILTER_AND_FLY" if context != "NO_PROPERTIES_FOUND" else "RESET",
                        "payload": {
                            "ids": ids_list[:10] if context != "NO_PROPERTIES_FOUND" else [],
                            "locality": filters.get('locality', ''),
                            "property_type": filters.get('property_type', ''),
                            "zoom": 13
                        }
                    }
                }
        
        return {
            "reply": result.get("reply", ""),
            "map_action": result.get("map_action")
        }
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå GEMINI ERROR: {error_msg}")
        
        # CRITICAL: Do NOT return hardcoded response
        # Instead, return error that forces frontend to retry
        raise HTTPException(
            status_code=500,
            detail=f"AI Brain Error: {error_msg}. Please ensure GEMINI_API_KEY is set correctly."
        )

def calculate_veridian_score(property_data: Dict, user_profile: Dict) -> Dict:
    """Calculate Veridian investment score"""
    rental_yield = property_data.get("rental_yield", 0)
    appreciation = property_data.get("appreciation", 0)
    litigation = property_data.get("litigation", 0)
    rera_status = property_data.get("rera_status", "Unknown")
    distance_metro = property_data.get("distance_metro", 10)
    
    # Normalize
    yield_norm = min(rental_yield / 7.0, 1.0)
    growth_norm = min(appreciation / 65.0, 1.0)
    legal_score = 1.0
    
    if litigation > 0:
        legal_score -= 0.3 * min(litigation, 3)
    if rera_status == "Revoked":
        legal_score -= 0.5
    legal_norm = max(0, legal_score)
    
    base_score = (yield_norm * 0.3) + (growth_norm * 0.4) + (legal_norm * 0.3)
    score = 1 + (base_score * 9)
    
    # User adjustments
    risk = user_profile.get("risk", "Moderate")
    warnings = []
    
    if risk == "Conservative" and (litigation > 0 or rera_status == "Revoked"):
        score = 1.0
        warnings.append("‚ö†Ô∏è Legal issues - Not suitable for conservative investors")
    
    if risk == "Aggressive" and distance_metro < 1.0:
        score = min(10.0, score + 1.5)
        warnings.append("üöÄ Metro proximity boost (+1.5)")
    
    verdict = "STRONG BUY" if score >= 8 else "BUY" if score >= 6 else "HOLD" if score >= 4 else "HIGH RISK"
    
    return {
        "score": round(score, 2),
        "breakdown": {
            "yield": round(yield_norm * 10, 2),
            "growth": round(growth_norm * 10, 2),
            "legal": round(legal_norm * 10, 2)
        },
        "verdict": verdict,
        "warnings": warnings
    }

# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.get("/")
def root():
    api_key_status = "‚úÖ Configured" if os.getenv("GOOGLE_API_KEY") else "‚ùå MISSING"
    return {
        "service": "Veridian API v3.0 - The Brain",
        "status": "operational",
        "properties_loaded": len(PROPERTIES_DATA),
        "gemini_status": api_key_status,
        "hardcoded_responses": 0
    }

@app.get("/api/properties")
def get_properties(
    locality: Optional[str] = None,
    property_type: Optional[str] = None,
    min_price: Optional[int] = None,
    max_price: Optional[int] = None,
    bedrooms: Optional[int] = None,
    limit: Optional[int] = 100
):
    """Get filtered properties"""
    filtered = PROPERTIES_DATA.copy()
    
    if locality:
        filtered = [p for p in filtered if p.get("locality") == locality]
    if property_type:
        filtered = [p for p in filtered if p.get("property_type") == property_type]
    if min_price:
        filtered = [p for p in filtered if p.get("price", 0) >= min_price]
    if max_price:
        filtered = [p for p in filtered if p.get("price", 0) <= max_price]
    if bedrooms:
        filtered = [p for p in filtered if p.get("bedrooms") == bedrooms]
    
    return {
        "count": len(filtered),
        "properties": filtered[:limit]
    }

@app.post("/api/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """
    THE BRAIN ENDPOINT
    STRICT RULE: Every response generated by Gemini, ZERO hardcoded text
    """
    try:
        # Step 1: Extract search criteria
        filters = extract_search_criteria(request.message)
        print(f"üîç Filters extracted: {filters}")
        
        # Step 2: Query DataFrame
        filtered_df = filter_properties_by_criteria(filters)
        print(f"üìä Found {len(filtered_df)} matching properties")
        
        # Step 3: Create context
        context = create_context_string(filtered_df)
        
        # Step 4: Call Gemini Brain (THE ONLY SOURCE OF RESPONSES)
        result = call_gemini_brain(
            request.message,
            context,
            filters,
            request.user_profile
        )
        
        print(f"üß† Gemini response generated")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Chat error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error: {str(e)}"
        )

@app.post("/api/score")
def calculate_score(request: ScoreRequest):
    """Calculate Veridian score for a property"""
    property_data = next((p for p in PROPERTIES_DATA if p["id"] == request.property_id), None)
    
    if not property_data:
        raise HTTPException(status_code=404, detail="Property not found")
    
    return calculate_veridian_score(property_data, request.user_profile)

@app.get("/api/property/{property_id}")
def get_property_by_id(property_id: str):
    """Get single property by ID"""
    property_data = next((p for p in PROPERTIES_DATA if p["id"] == property_id), None)
    
    if not property_data:
        raise HTTPException(status_code=404, detail="Property not found")
    
    return property_data

# Vercel handler
handler = app
